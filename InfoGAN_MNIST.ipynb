{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InfoGAN-MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPky+kOdVF01v3cG4Z9GDxW"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l9vCXC_Ch2Gd",
        "outputId": "38b9178d-9674-4cf8-a644-f2d20f6015b7"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ofh4hVxzAZP"
      },
      "source": [
        "# Import libraries.\n",
        "import os\n",
        "import time\n",
        "from math import sqrt\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from numpy.random import randn, randint\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import RandomNormal\n",
        "from numpy import zeros, ones, expand_dims, hstack\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Activation"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RBLi9iGJVpp"
      },
      "source": [
        "!pip install -q imageio\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODwtMRS1FNZg"
      },
      "source": [
        "# Download the Fashion MNIST dataset.\n",
        "(train_images, train_labels), (test_images, test_labels) =  tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "188wMzPHFiG-"
      },
      "source": [
        "# Pre-process the 60,000 training set images.\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') # Convert pixels to floating point values. \n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize the pixel values to be in the range of [-1,1].\n",
        "train_dataset = train_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1j_PpNQFncM"
      },
      "source": [
        "# Perform hyperparameter optimization.\n",
        "BATCH = 256\n",
        "EPOCHS = 10\n",
        "LATENT_DIM = 62\n",
        "N_CAT = 10\n",
        "SAMPLES = 100"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBFBR0gVGAb-"
      },
      "source": [
        "# Define the generator.\n",
        "def build_generator(input_size):\n",
        "\tinit = RandomNormal(stddev=0.02) # Initialize with random Gaussian weights.\n",
        "\tinput_latent = Input(shape=(input_size,))\n",
        "  # Add a fully connected layer to take the input vector and produce a some numbers of activations to create 512 7Ã—7.\n",
        "\tnodes = 512 * 7 * 7\n",
        "\tgen = Dense(nodes, kernel_initializer=init)(input_latent) \n",
        "\tgen = Activation('relu')(gen) \n",
        "\tgen = BatchNormalization()(gen)\n",
        "\tgen = Reshape((7, 7, 512))(gen)\n",
        "  # Upsample with normal convolution layers.\n",
        "\tgen = Conv2D(128, (4,4), padding='same', kernel_initializer=init)(gen)\n",
        "\tgen = Activation('relu')(gen)\n",
        "\tgen = BatchNormalization()(gen)\n",
        "\tgen = Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
        "\tgen = Activation('relu')(gen)\n",
        "\tgen = BatchNormalization()(gen)\n",
        "\tgen = Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
        "\toutput_layer = Activation('tanh')(gen)\n",
        "\tmodel = Model(input_latent, output_layer) # Define the model.\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TlEnIheGKqM"
      },
      "source": [
        "# Build the generator.\n",
        "input_size = LATENT_DIM + N_CAT\n",
        "generator = build_generator(input_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEL200lmF0H_"
      },
      "source": [
        "# Define the discriminator.\n",
        "def build_discriminator(n_cat, input_shape=(28,28,1)):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tinput_image = Input(shape=input_shape)\n",
        "\t# Downsample using Conv2D and LeakyReLU.\n",
        "\tdisc = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(input_image)\n",
        "\tdisc = LeakyReLU(alpha=0.1)(disc)\n",
        "\tdisc = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(disc)\n",
        "\tdisc = LeakyReLU(alpha=0.1)(disc)\n",
        "\tdisc = BatchNormalization()(disc)\n",
        "\tdisc = Conv2D(256, (4,4), padding='same', kernel_initializer=init)(disc)\n",
        "\tdisc = LeakyReLU(alpha=0.1)(disc)\n",
        "\tdisc = BatchNormalization()(disc)\n",
        "\tdisc = Flatten()(disc) # Flatten the feature maps. \n",
        "\tclassifier = Dense(1, activation='sigmoid')(disc) \t# Predict the probability of an output being real or fake with the sigmoid activation function.\n",
        "\t# Define and compile the model with an Adam optimizer.\n",
        "\tdiscriminator = Model(input_image, classifier)\n",
        "\tdiscriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "\t# Create the auxiliary model layers.\n",
        "\taux = Dense(128)(disc)\n",
        "\taux = BatchNormalization()(aux)\n",
        "\taux = LeakyReLU(alpha=0.1)(aux)\n",
        "\tcodes = Dense(n_cat, activation='softmax')(aux) # Predict the control variable using the softmax activation function.\n",
        "\tauxiliary = Model(input_image, codes) # Define the model.\n",
        "\treturn discriminator, auxiliary"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yK85ADEVQqc"
      },
      "source": [
        "# Build the discriminator.\n",
        "discriminator, auxiliary = build_discriminator(N_CAT)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCAK8gyxVpiT"
      },
      "source": [
        "# Define the InfoGAN.\n",
        "def build_infogan(generator, discriminator, auxiliary):\n",
        "\tdiscriminator.trainable = False\n",
        "\t# Connect the output of the generator to the input of the discriminator and auxiliary models.\n",
        "\tdiscriminator_output = discriminator(generator.output)\n",
        "\tauxiliary_output = auxiliary(generator.output)\n",
        "\t# Define the composite model with an Adam optimizer.\n",
        "\tmodel = Model(generator.input, [discriminator_output, auxiliary_output])\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3-TffslXJdL"
      },
      "source": [
        "# Build the InfoGAN.\n",
        "infogan = build_infogan(generator, discriminator, auxiliary)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_BPe5lwXYxZ"
      },
      "source": [
        "# Produce points in the latent space as input for the generator.\n",
        "def get_latent_points(latent_dim, n_cat, samples):\n",
        "\tz_latent = randn(latent_dim * samples)\n",
        "\tz_latent = z_latent.reshape(samples, latent_dim)\n",
        "\tcodes = randint(0, n_cat, samples)\n",
        "\tcodes = to_categorical(codes, num_classes=n_cat)\n",
        "\tz_input = hstack((z_latent, codes)) # Concatenate the latent points and control codes.\n",
        "\treturn [z_input, codes]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOkiQmG9a15b"
      },
      "source": [
        "# Select real samples from the dataset.\n",
        "def get_real_samples(train_dataset, samples):\n",
        "\tindex = randint(0, train_dataset.shape[0], samples)\n",
        "\tx = train_dataset[index]\n",
        "\ty = ones((samples, 1))  # Generate class labels of value 1 to indicate the images are real.\n",
        "\treturn x, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCBaYkY7bBy1"
      },
      "source": [
        "# Generate fake images with class labels using the generator.\n",
        "def get_fake_samples(generator, latent_dim, n_cat, samples):\n",
        "\tz_input, _ = get_latent_points(latent_dim, n_cat, samples)\n",
        "\timages = generator.predict(z_input)\n",
        "\ty = zeros((samples, 1)) # Generate class labels of value 0 to indicate the images are fake.\n",
        "\treturn images, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxRFq5ZabpE-"
      },
      "source": [
        "# Periodically use the generator to generate a sample of images and save the generator and composite models to a file.\n",
        "def summarize_performance(step, generator, infogan, latent_dim, n_cat, samples=100):\n",
        "  examples, _ = get_fake_samples(generator, latent_dim, n_cat, samples)\n",
        "\t# Scale images from [-1,1] to [0,1].\n",
        "  examples = (examples + 1) / 2.0\n",
        "  fig = pyplot.figure(figsize=(10,10))\n",
        "  # Plot the images.\n",
        "  for i in range(100):\n",
        "    pyplot.subplot(10, 10, i+1)\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(examples[i, :, :, 0], cmap='gray')\n",
        "  # Save the plot to a file.\n",
        "  pyplot.savefig('image_at_epoch_{:04d}.png'.format(step+1))\n",
        "  pyplot.show()\n",
        "  pyplot.close()\n",
        "  # Save the generator.\n",
        "  filename2 = 'generator_%04d.h5' % (step+1)\n",
        "  generator.save(filename2)\n",
        "  # Save the InfoGAN.\n",
        "  filename3 = 'infogan_%04d.h5' % (step+1)\n",
        "  infogan.save(filename3)\n",
        "  checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "  print('>Saved: %s, %s, and %s' % (filename1, filename2, filename3))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ekj4dKEIvugZ"
      },
      "source": [
        "# Save checkpoints during training so the model can be restored.\n",
        "checkpoint_dir = '/content/gdrive/My Drive/Fashion Synthesis/InfoGAN'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=Adam(lr=0.0002, beta_1=0.5), discriminator_optimizer=Adam(lr=0.0002, beta_1=0.5), generator=generator, discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fqLfvx0b2li"
      },
      "source": [
        "# Iterate over the number of epochs and train the InfoGAN on the dataset in batches.\n",
        "def train(generator, discriminator, infogan, train_dataset, latent_dim, n_cat, epochs, batch):\n",
        "  batch_per_epoch = int(train_dataset.shape[0] / batch)\n",
        "  steps = batch_per_epoch * epochs\n",
        "  half_batch = int(batch / 2)\n",
        "  start = time.time() # Get the starting time of each epoch.\n",
        "  epoch = 0\n",
        "  for step in range(steps):\n",
        "    # Update the discriminator and auxiliary model weights using randomly selected real images.\n",
        "    x_real, y_real = get_real_samples(train_dataset, half_batch)\n",
        "    d_loss1 = discriminator.train_on_batch(x_real, y_real)\n",
        "    # Update discriminator model weights using fake images.\n",
        "    x_fake, y_fake = get_fake_samples(generator, latent_dim, n_cat, half_batch)\n",
        "    d_loss2 = discriminator.train_on_batch(x_fake, y_fake)\n",
        "    # Update the generator based on the the discriminator and auxiliary models' errors.\n",
        "    z_input, codes = get_latent_points(latent_dim, n_cat, batch)\n",
        "    y_infogan = ones((batch, 1))\n",
        "    _,g_1,g_2 = infogan.train_on_batch(z_input, [y_infogan, codes])\n",
        "    # print('>%d, discriminator loss: [%.3f,%.3f], generator loss: [%.3f] auxiliary loss: [%.3f]' % (step+1, d_loss1, d_loss2, g_1, g_2))\n",
        "    # Evaluate the model's performance during every epoch.\n",
        "    if (step+1) % (batch_per_epoch*10) == 0:\n",
        "      epoch += 1\n",
        "      summarize_performance(step, generator, infogan, latent_dim, n_cat, epoch)\n",
        "      print('Time for epoch {} is {} seconds.'.format(epoch, time.time()-start)) # Record how long it took for each epoch to run.\n",
        "      start = time.time() # Get the starting time of each epoch."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "kBup49kJe3yn"
      },
      "source": [
        "train(generator, discriminator, infogan, train_dataset, LATENT_DIM, N_CAT, EPOCHS, BATCH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "CCCEK98uxCLw"
      },
      "source": [
        "# Restore training from the latest saved checkpoint.\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "gE27LtYpf6Ix"
      },
      "source": [
        "# Create a plot of generated images\n",
        "def create_plot(examples, n_examples):\n",
        "  fig = pyplot.figure(figsize=(10,10))\n",
        "  for i in range(n_examples):\n",
        "    pyplot.subplot(sqrt(n_examples), sqrt(n_examples), 1 + i)\n",
        "    pyplot.axis('off')\n",
        "    pyplot.imshow(examples[i, :, :, 0], cmap='gray')\n",
        "# Load the trained model.\n",
        "model = load_model('generator_0234.h5', compile=False)\n",
        "CATEGORY = 9 # Define the category that will be evaluated.\n",
        "z_input, _ = get_latent_points(LATENT_DIM, N_CAT, SAMPLES)\n",
        "examples = model.predict(z_input)\n",
        "examples = (examples + 1) / 2.0 # Scale from [-1,1] to [0,1]\n",
        "create_plot(examples, SAMPLES)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_AH85ZEcKR7v"
      },
      "source": [
        "# Create a gif using all the saved images.\n",
        "gif_file = 'infogan_fashion_mnist.gif'\n",
        "with imageio.get_writer(gif_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "embed.embed_file(gif_file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}