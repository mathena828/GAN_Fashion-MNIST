{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "InfoGAN-MNIST",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOspq+H/45nogEPdk0aJIo4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mathena828/GAN_Fashion-MNIST/blob/main/InfoGAN_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ofh4hVxzAZP"
      },
      "source": [
        "# Import libraries.\n",
        "import time\n",
        "from math import sqrt\n",
        "import tensorflow as tf\n",
        "from matplotlib import pyplot\n",
        "from keras.optimizers import Adam\n",
        "from keras.utils import to_categorical\n",
        "from numpy.random import randn, randint\n",
        "from keras.models import Model, load_model\n",
        "from keras.initializers import RandomNormal\n",
        "from numpy import zeros, ones, expand_dims, hstack\n",
        "from keras.layers import Input, Dense, Reshape, Flatten, Conv2D, Conv2DTranspose, LeakyReLU, BatchNormalization, Activation"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ODwtMRS1FNZg"
      },
      "source": [
        "# Download the Fashion MNIST dataset.\n",
        "(train_images, train_labels), (test_images, test_labels) =  tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "188wMzPHFiG-"
      },
      "source": [
        "# Pre-process the 60,000 training set images.\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') # Convert pixels to floating point values. \n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize the pixel values to be in the range of [-1,1].\n",
        "train_dataset = train_images"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c1j_PpNQFncM"
      },
      "source": [
        "# Perform hyperparameter optimization.\n",
        "BATCH = 256\n",
        "EPOCHS = 50 \n",
        "LATENT_DIM = 62\n",
        "N_CAT = 10\n",
        "SAMPLES = 100"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SBFBR0gVGAb-"
      },
      "source": [
        "# Define the generator.\n",
        "def build_generator(input_size):\n",
        "\tinit = RandomNormal(stddev=0.02) # Initialize with random Gaussian weights.\n",
        "\tinput_latent = Input(shape=(input_size,))\n",
        "  # Add a fully connected layer to take the input vector and produce a some numbers of activations to create 512 7Ã—7.\n",
        "\tnodes = 512 * 7 * 7\n",
        "\tgen = Dense(nodes, kernel_initializer=init)(input_latent) \n",
        "\tgen = Activation('relu')(gen) \n",
        "\tgen = BatchNormalization()(gen)\n",
        "\tgen = Reshape((7, 7, 512))(gen)\n",
        "  # Upsample with normal convolution layers.\n",
        "\tgen = Conv2D(128, (4,4), padding='same', kernel_initializer=init)(gen)\n",
        "\tgen = Activation('relu')(gen)\n",
        "\tgen = BatchNormalization()(gen)\n",
        "\tgen = Conv2DTranspose(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
        "\tgen = Activation('relu')(gen)\n",
        "\tgen = BatchNormalization()(gen)\n",
        "\tgen = Conv2DTranspose(1, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(gen)\n",
        "\toutput_layer = Activation('tanh')(gen)\n",
        "\tmodel = Model(input_latent, output_layer) # Define the model.\n",
        "\treturn model"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9TlEnIheGKqM"
      },
      "source": [
        "# Build the generator.\n",
        "input_size = LATENT_DIM + N_CAT\n",
        "generator = build_generator(input_size)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FEL200lmF0H_"
      },
      "source": [
        "# Define the discriminator.\n",
        "def build_discriminator(n_cat, input_shape=(28,28,1)):\n",
        "\tinit = RandomNormal(stddev=0.02)\n",
        "\tinput_image = Input(shape=input_shape)\n",
        "\t# Downsample using Conv2D and LeakyReLU.\n",
        "\tdisc = Conv2D(64, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(input_image)\n",
        "\tdisc = LeakyReLU(alpha=0.1)(disc)\n",
        "\tdisc = Conv2D(128, (4,4), strides=(2,2), padding='same', kernel_initializer=init)(disc)\n",
        "\tdisc = LeakyReLU(alpha=0.1)(disc)\n",
        "\tdisc = BatchNormalization()(disc)\n",
        "\tdisc = Conv2D(256, (4,4), padding='same', kernel_initializer=init)(disc)\n",
        "\tdisc = LeakyReLU(alpha=0.1)(disc)\n",
        "\tdisc = BatchNormalization()(disc)\n",
        "\tdisc = Flatten()(disc) # Flatten the feature maps. \n",
        "\tclassifier = Dense(1, activation='sigmoid')(disc) \t# Predict the probability of an output being real or fake with the sigmoid activation function.\n",
        "\t# Define and compile the model with an Adam optimizer.\n",
        "\tdiscriminator = Model(input_image, classifier)\n",
        "\tdiscriminator.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n",
        "\t# Create the auxiliary model layers.\n",
        "\taux = Dense(128)(disc)\n",
        "\taux = BatchNormalization()(aux)\n",
        "\taux = LeakyReLU(alpha=0.1)(aux)\n",
        "\tcodes = Dense(n_cat, activation='softmax')(aux) # Predict the control variable using the softmax activation function.\n",
        "\tauxiliary = Model(input_image, codes) # Define the model.\n",
        "\treturn discriminator, auxiliary"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6yK85ADEVQqc"
      },
      "source": [
        "# Build the discriminator.\n",
        "discriminator, auxiliary = build_discriminator(N_CAT)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HCAK8gyxVpiT"
      },
      "source": [
        "# Define the InfoGAN.\n",
        "def build_infogan(generator, discriminator, auxiliary):\n",
        "\tdiscriminator.trainable = False\n",
        "\t# Connect the output of the generator to the input of the discriminator and auxiliary models.\n",
        "\tdiscriminator_output = discriminator(generator.output)\n",
        "\tauxiliary_output = auxiliary(generator.output)\n",
        "\t# Define the composite model with an Adam optimizer.\n",
        "\tmodel = Model(generator.input, [discriminator_output, auxiliary_output])\n",
        "\topt = Adam(lr=0.0002, beta_1=0.5)\n",
        "\tmodel.compile(loss=['binary_crossentropy', 'categorical_crossentropy'], optimizer=opt)\n",
        "\treturn model"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u3-TffslXJdL"
      },
      "source": [
        "# Build the InfoGAN.\n",
        "infogan = build_infogan(generator, discriminator, auxiliary)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f_BPe5lwXYxZ"
      },
      "source": [
        "# Produce points in the latent space as input for the generator.\n",
        "def get_latent_points(latent_dim, n_cat, samples):\n",
        "\tz_latent = randn(latent_dim * samples)\n",
        "\tz_latent = z_latent.reshape(samples, latent_dim)\n",
        "\tcodes = randint(0, n_cat, samples)\n",
        "\tcodes = to_categorical(codes, num_classes=n_cat)\n",
        "\tz_input = hstack((z_latent, codes)) # Concatenate the latent points and control codes.\n",
        "\treturn [z_input, codes]"
      ],
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KOkiQmG9a15b"
      },
      "source": [
        "# Select real samples from the dataset.\n",
        "def get_real_samples(train_dataset, samples):\n",
        "\tindex = randint(0, train_dataset.shape[0], samples)\n",
        "\tx = train_dataset[index]\n",
        "\ty = ones((samples, 1))  # Generate class labels of value 1 to indicate the images are real.\n",
        "\treturn x, y"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TCBaYkY7bBy1"
      },
      "source": [
        "# Generate fake images with class labels using the generator.\n",
        "def get_fake_samples(generator, latent_dim, n_cat, samples):\n",
        "\tz_input, _ = get_latent_points(latent_dim, n_cat, samples)\n",
        "\timages = generator.predict(z_input)\n",
        "\ty = zeros((samples, 1)) # Generate class labels of value 0 to indicate the images are fake.\n",
        "\treturn images, y"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WxRFq5ZabpE-"
      },
      "source": [
        "# Periodically use the generator to generate a sample of images and save the generator and composite models to a file.\n",
        "def summarize_performance(step, generator, infogan, latent_dim, n_cat, samples=100):\n",
        "\tfakes, _ = get_fake_samples(generator, latent_dim, n_cat, samples)\n",
        "\tfakes = (fakes + 1) / 2.0 \t# Scale from [-1,1] to [0,1]\n",
        "  # Plot the images.\n",
        "\tfor i in range(100):\n",
        "\t\tpyplot.subplot(10, 10, 1 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(X[i, :, :, 0], cmap='gray')\n",
        "\t# Save the plot to a file.\n",
        "\tfilename1 = 'generated_plot_%04d.png' % (step+1)\n",
        "\tpyplot.savefig(filename1)\n",
        "\tpyplot.close()\n",
        "\t# Save the generator.\n",
        "\tfilename2 = 'generator_%04d.h5' % (step+1)\n",
        "\tgenerator.save(filename2)\n",
        "\t# Save the InfoGAN.\n",
        "\tfilename3 = 'infogan_%04d.h5' % (step+1)\n",
        "\tgan_model.save(filename3)\n",
        "\tprint('>Saved: %s, %s, and %s' % (filename1, filename2, filename3))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3fqLfvx0b2li"
      },
      "source": [
        "# Iterate over the number of epochs and train the InfoGAN on the dataset in batches.\n",
        "def train(generator, discriminator, infogan, train_dataset, latent_dim, n_cat, epochs, batch):\n",
        "  batch_per_epoch = int(train_dataset.shape[0] / batch)\n",
        "  steps = batch_per_epoch * epochs\n",
        "  half_batch = int(batch / 2)\n",
        "  start = time.time() # Get the starting time of each epoch.\n",
        "  for step in range(steps):\n",
        "    # Update the discriminator and auxiliary model weights using randomly selected real images.\n",
        "    x_real, y_real = get_real_samples(train_dataset, half_batch)\n",
        "    d_loss1 = discriminator.train_on_batch(x_real, y_real)\n",
        "    # Update discriminator model weights using fake images.\n",
        "    x_fake, y_fake = get_fake_samples(generator, latent_dim, n_cat, half_batch)\n",
        "    d_loss2 = discriminator.train_on_batch(x_fake, y_fake)\n",
        "    # Update the generator based on the the discriminator and auxiliary models' errors.\n",
        "    z_input, codes = get_latent_points(latent_dim, n_cat, batch)\n",
        "    y_infogan = ones((batch, 1))\n",
        "    _,g_1,g_2 = infogan.train_on_batch(z_input, [y_infogan, codes])\n",
        "    # print('>%d, d[%.3f,%.3f], g[%.3f] q[%.3f]' % (step+1, d_loss1, d_loss2, g_1, g_2))\n",
        "    # Evaluate the model's performance during every epoch.\n",
        "    if (step+1) % (batch_per_epoch * 10) == 0:\n",
        "      summarize_performance(step, generator, infogan, latent_dim, n_cat)\n",
        "      print('Time for epoch {} is {} seconds.'.format(epoch + 1, time.time()-start)) # Record how long it took for each epoch to run.\n",
        "      start = time.time() # Get the starting time of each epoch."
      ],
      "execution_count": 49,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kBup49kJe3yn"
      },
      "source": [
        "train(generator, discriminator, infogan, train_dataset, LATENT_DIM, N_CAT, EPOCHS, BATCH)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gE27LtYpf6Ix"
      },
      "source": [
        "# Create a plot of generated images\n",
        "def create_plot(examples, n_examples):\n",
        "\tfor i in range(n_examples):\n",
        "\t\tpyplot.subplot(sqrt(n_examples), sqrt(n_examples), 1 + i)\n",
        "\t\tpyplot.axis('off')\n",
        "\t\tpyplot.imshow(examples[i, :, :, 0], cmap='gray')\n",
        "\tpyplot.show()\n",
        " \n",
        "# Load the trained model.\n",
        "model = load_model('model.h5', compile=False)\n",
        "CATEGORY = 9 # Define the category that will be evaluated.\n",
        "z_input, _ = get_latent_points(LATENT_DIM, N_CAT, SAMPLES, CATEGORY)\n",
        "X = model.predict(z_input)\n",
        "X = (X + 1) / 2.0 # Scale from [-1,1] to [0,1]\n",
        "create_plot(X, SAMPLES)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}