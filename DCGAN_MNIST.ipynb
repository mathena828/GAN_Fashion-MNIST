{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "DCGAN-MNIST.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOzczibdjz+04J7ek/EboXF"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylzzFrYKXgqM",
        "outputId": "ce73bd32-8d24-4fed-eecb-5b3c29a23fab"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niHVoyNADT5k",
        "outputId": "1d8a6b97-0670-455e-aaaa-8a45918112e0"
      },
      "source": [
        "!pip install -q imageio\n",
        "!pip install -q git+https://github.com/tensorflow/docs"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[?25l\r\u001b[K     |▎                               | 10kB 18.5MB/s eta 0:00:01\r\u001b[K     |▋                               | 20kB 23.8MB/s eta 0:00:01\r\u001b[K     |█                               | 30kB 10.6MB/s eta 0:00:01\r\u001b[K     |█▎                              | 40kB 9.6MB/s eta 0:00:01\r\u001b[K     |█▋                              | 51kB 8.6MB/s eta 0:00:01\r\u001b[K     |██                              | 61kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▎                             | 71kB 8.4MB/s eta 0:00:01\r\u001b[K     |██▋                             | 81kB 8.0MB/s eta 0:00:01\r\u001b[K     |██▉                             | 92kB 8.1MB/s eta 0:00:01\r\u001b[K     |███▏                            | 102kB 7.9MB/s eta 0:00:01\r\u001b[K     |███▌                            | 112kB 7.9MB/s eta 0:00:01\r\u001b[K     |███▉                            | 122kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▏                           | 133kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▌                           | 143kB 7.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 153kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 163kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▌                          | 174kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 184kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████                          | 194kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▍                         | 204kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████▊                         | 215kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████                         | 225kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▍                        | 235kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 245kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████                        | 256kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▍                       | 266kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 276kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████                       | 286kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 296kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████▋                      | 307kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████                      | 317kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 327kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████▋                     | 337kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████                     | 348kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 358kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▌                    | 368kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████▉                    | 378kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 389kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 399kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████▉                   | 409kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▏                  | 419kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▌                  | 430kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 440kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▏                 | 450kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▍                 | 460kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 471kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 481kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▍                | 491kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████▊                | 501kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████                | 512kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 522kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 532kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 542kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 552kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▋              | 563kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 573kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 583kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▋             | 593kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 604kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▎            | 614kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████▋            | 624kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 634kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▏           | 645kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 655kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 665kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▏          | 675kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▌          | 686kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 696kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▏         | 706kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 716kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 727kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████         | 737kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 747kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▊        | 757kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 768kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▍       | 778kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 788kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 798kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▍      | 808kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 819kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 829kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 839kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▋     | 849kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████     | 860kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▎    | 870kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▋    | 880kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████    | 890kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▎   | 901kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 911kB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▉   | 921kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 931kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▌  | 942kB 7.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▉  | 952kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▏ | 962kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▌ | 972kB 7.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 983kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 993kB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▌| 1.0MB 7.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▊| 1.0MB 7.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 1.0MB 7.9MB/s \n",
            "\u001b[?25h  Building wheel for tensorflow-docs (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Uufs4ewnDcZY"
      },
      "source": [
        "# Import libraries.\n",
        "import os\n",
        "import PIL\n",
        "import glob\n",
        "import time\n",
        "import imageio\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from IPython import display\n",
        "import matplotlib.pyplot as plt\n",
        "from tensorflow.keras import layers\n",
        "from keras.preprocessing import image\n",
        "import tensorflow_docs.vis.embed as embed"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhP9bclnepL_",
        "outputId": "0ec4d60a-be14-43db-a125-b43ccda73aa0"
      },
      "source": [
        "# Download the Fashion MNIST dataset.\n",
        "(train_images, train_labels), (test_images, test_labels) =  tf.keras.datasets.fashion_mnist.load_data()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "8192/5148 [===============================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bzAN0l7-eyqA"
      },
      "source": [
        "# Pre-process the 60,000 training set images.\n",
        "train_images = train_images.reshape(train_images.shape[0], 28, 28, 1).astype('float32') # Convert pixels to floating point values. \n",
        "train_images = (train_images - 127.5) / 127.5 # Normalize the pixel values to be in the range of [-1,1]."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cepTbRspfTQW"
      },
      "source": [
        "# Perform hyperparameter optimization.\n",
        "BUFFER_SIZE = 60000\n",
        "BATCH_SIZE = 256\n",
        "EPOCHS = 10 \n",
        "NOISE_DIM = 100\n",
        "EXAMPLES = 100\n",
        "# Define a random seed value that will be used to produce images.\n",
        "seed = tf.random.normal([EXAMPLES, NOISE_DIM])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "N-MBXwc2fW4a"
      },
      "source": [
        "# Shuffle then batch the dataset.\n",
        "train_dataset = tf.data.Dataset.from_tensor_slices(train_images).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y9rd0WjmfYaK"
      },
      "source": [
        "# Define the generator.\n",
        "def build_generator():\n",
        "    model = tf.keras.Sequential() # Initialize a sequential model object.\n",
        "    model.add(layers.Dense(7*7*256, use_bias=False, input_shape=(100,))) # Add a densely connected neural network layer.\n",
        "    # Batch Normalization is used to scale the mean and variances of the layer's inputs.\n",
        "    model.add(layers.BatchNormalization())\n",
        "    # Leaky Rectified Linear Units are used to increase the range of the ReLu function.\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Reshape((7, 7, 256)))\n",
        "    assert model.output_shape == (None, 7, 7, 256) \n",
        "    # Add a series of transposed convolution layers.\n",
        "    model.add(layers.Conv2DTranspose(128, (5, 5), strides=(1, 1), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 7, 7, 128)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2DTranspose(64, (5, 5), strides=(2, 2), padding='same', use_bias=False))\n",
        "    assert model.output_shape == (None, 14, 14, 64)\n",
        "    model.add(layers.BatchNormalization())\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Conv2DTranspose(1, (5, 5), strides=(2, 2), padding='same', use_bias=False, activation='tanh'))\n",
        "    assert model.output_shape == (None, 28, 28, 1) # Upsample until the target shape (None,28,28,1), where None is the batch size, is reached.\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ige3Eg4efjpd"
      },
      "source": [
        "# Build the generator.\n",
        "generator = build_generator()\n",
        "generator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Wc2MQXp8fwO9"
      },
      "source": [
        "# Define the discriminator.\n",
        "def build_discriminator():\n",
        "    model = tf.keras.Sequential() # Initialize a sequential model object.\n",
        "    # Create a CNN-based image classifier.\n",
        "    model.add(layers.Conv2D(64, (5, 5), strides=(2, 2), padding='same', input_shape=[28, 28, 1]))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    # Add a droupout to prevent overfitting.\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    model.add(layers.Conv2D(128, (5, 5), strides=(2, 2), padding='same'))\n",
        "    model.add(layers.LeakyReLU())\n",
        "    model.add(layers.Dropout(0.3))\n",
        "    # Flatten the output of the last convolutional layer and pass it to the dense layer.\n",
        "    model.add(layers.Flatten())\n",
        "    model.add(layers.Dense(1))\n",
        "    return model "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "95vWa62yf2br"
      },
      "source": [
        "# Build the discriminator.\n",
        "discriminator = build_discriminator()\n",
        "discriminator.summary()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9Gs6ARKf7Sy"
      },
      "source": [
        "# Define a helper fucntion to calculate the cross entropy loss.\n",
        "cross_entropy = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
        "# Measure how well the discriminator can distinguish real (1) from fake (0) images.\n",
        "def discriminator_loss(real, fake):\n",
        "    real_loss = cross_entropy(tf.ones_like(real), real) # Compare the binary predictions of the discriminator on real images to a tensor of all ones with the same shape.\n",
        "    fake_loss = cross_entropy(tf.zeros_like(fake), fake) # Compare the binary predictions of the discriminator on fake images to a tensor of all zeroes with the same shape.\n",
        "    total_loss = real_loss + fake_loss\n",
        "    return total_loss\n",
        "# Measure how well the generator can trick the discriminator.\n",
        "def generator_loss(fake):\n",
        "    return cross_entropy(tf.ones_like(fake), fake) # Compare the binary predictions of the discriminator on fake images to a tensor of all ones with the same shape."
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O05Fi5g2gIHO"
      },
      "source": [
        "# Define two seperate Adam optimizers for the generator and discriminator.\n",
        "generator_optimizer = tf.keras.optimizers.Adam(1e-4)\n",
        "discriminator_optimizer = tf.keras.optimizers.Adam(1e-4)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oWyb5TEwgLUN"
      },
      "source": [
        "# Save checkpoints during training so the model can be restored.\n",
        "checkpoint_dir = '/content/gdrive/My Drive/Fashion Synthesis/DCGAN'\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"checkpoint\")\n",
        "checkpoint = tf.train.Checkpoint(generator_optimizer=generator_optimizer, discriminator_optimizer=discriminator_optimizer, generator=generator, discriminator=discriminator)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OADq5nmegXOV"
      },
      "source": [
        "# Define a method to generate and save fake images after training. \n",
        "def generate_and_save_images(model, epoch, test_input):\n",
        "  predictions = model(test_input, training=False)\n",
        "  fig = plt.figure(figsize=(10,10))\n",
        "  for i in range(predictions.shape[0]):\n",
        "      plt.subplot(10, 10, i+1)\n",
        "      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='gray')\n",
        "      plt.axis('off')\n",
        "  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FL7909u8m9qT"
      },
      "source": [
        "# Define a method that will return an image from a specific epoch.\n",
        "def display_image(epoch):\n",
        "  return PIL.Image.open('image_at_epoch_{:04d}.png'.format(epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_6piD3FegPje"
      },
      "source": [
        "@tf.function # Compile the function into a callable TensorFlow graph.\n",
        "def train_step(images):\n",
        "    # Generate an image from some random noise.\n",
        "    noise = tf.random.normal([BATCH_SIZE, NOISE_DIM])\n",
        "    with tf.GradientTape() as gen_tape, tf.GradientTape() as disc_tape:\n",
        "      generated_images = generator(noise, training=True)\n",
        "    # The discriminator classifies the real images from the training set and the fake images produced by the discriminator.\n",
        "      real = discriminator(images, training=True)\n",
        "      fake= discriminator(generated_images, training=True)\n",
        "    # Calculate the losses of the generator and the discriminator. \n",
        "      gen_loss = generator_loss(fake)\n",
        "      disc_loss = discriminator_loss(real, fake)\n",
        "    # Calculate the gradients of the loss functions with GradientTape.\n",
        "    gradients_of_generator = gen_tape.gradient(gen_loss, generator.trainable_variables)\n",
        "    gradients_of_discriminator = disc_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
        "    # Apply the optimizers to find the weights that minimize the losses. Update the generator and discriminator accordingly.\n",
        "    generator_optimizer.apply_gradients(zip(gradients_of_generator, generator.trainable_variables))\n",
        "    discriminator_optimizer.apply_gradients(zip(gradients_of_discriminator, discriminator.trainable_variables))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lKXSkjZZgWKJ"
      },
      "source": [
        "# Iterate over the number of epochs and train the DCGAN on the dataset in batches.\n",
        "def train(dataset, epochs):\n",
        "  for epoch in range(epochs):\n",
        "    start = time.time() # Get the starting time of each epoch.\n",
        "    for image_batch in dataset:\n",
        "      train_step(image_batch)\n",
        "    # Produce images for each training step.\n",
        "    display.clear_output(wait=True)\n",
        "    generate_and_save_images(generator, epoch + 1, seed)\n",
        "    # Save the model every 10 epochs.\n",
        "    # if (epoch + 1) % 10 == 0:\n",
        "    #   checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    # Save the model every epoch.\n",
        "    checkpoint.save(file_prefix = checkpoint_prefix)\n",
        "    print ('Time for epoch {} is {} seconds.'.format(epoch + 1, time.time()-start)) # Record how long it took for each epoch to run.\n",
        "  # Produce an image for the final epoch.\n",
        "  display.clear_output(wait=True)\n",
        "  generate_and_save_images(generator, epochs, seed)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wAZ1yZ3AgbuJ"
      },
      "source": [
        "# Train the generator and discriminator simultaneously.\n",
        "train(train_dataset, EPOCHS)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kc4YhovJykte",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92680ee7-87c1-415e-cf3b-085e4af2e158"
      },
      "source": [
        "# Restore training from the latest saved checkpoint.\n",
        "checkpoint.restore(tf.train.latest_checkpoint(checkpoint_dir))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x7fca7e5c32e8>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rz91W0ErnTEC"
      },
      "source": [
        "# Create a gif using all the saved images.\n",
        "gif_file = 'dcgan_fashion_mnist.gif'\n",
        "with imageio.get_writer(gif_file, mode='I') as writer:\n",
        "  filenames = glob.glob('image*.png')\n",
        "  filenames = sorted(filenames)\n",
        "  for filename in filenames:\n",
        "    image = imageio.imread(filename)\n",
        "    writer.append_data(image)\n",
        "  image = imageio.imread(filename)\n",
        "  writer.append_data(image)\n",
        "embed.embed_file(gif_file)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}